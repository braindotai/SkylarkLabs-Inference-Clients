[tool.poetry]
name = "skylarklabs-inference-client"
version = "0.1.0"
description = "Inference client library for running production deep learning models on both Triton Inference Server and Monolythic ONNX Server"
authors = ["Rishik Mourya <rishik@skylarklabs.ai>"]
license = "MIT"
readme = "README.md"
packages = [{include = "skylarklabs_inference_client"}]

[tool.poetry.dependencies]
python = "3.9.16"
attrdict = "^2.0.1"
requests = "^2.28.1"
rich = "^12.6.0"
numpy = "^1.24.1"
pillow = "^9.3.0"
onnxruntime-gpu = "^1.13.1"
tritonclient = {extras = ["grpc"], version = "^2.29.0"}
opencv-contrib-python = "^4.6.0.66"
torch = "^1.13.1"
torchvision = "^0.14.1"

[tool.poetry.group.dev.dependencies]
pytest = "^7.2.1"
flake8 = "^6.0.0"
tox = "^4.3.5"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
